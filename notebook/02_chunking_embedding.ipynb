{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c835317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/02_chunking_embedding.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))\n",
    "\n",
    "from vector_store_utils import load_embedding_model, create_and_index_faiss, load_faiss_index, semantic_search_faiss\n",
    "from data_preparation import load_complaint_data # To load the filtered data\n",
    "\n",
    "\n",
    "# --- Task 2: Text Chunking, Embedding, and Vector Store Indexing ---\n",
    "\n",
    "# Define paths\n",
    "FILTERED_DATA_PATH = '../data/filtered_complaints.csv'\n",
    "VECTOR_STORE_DIR = '../vector_store'\n",
    "\n",
    "# Load the cleaned and filtered dataset\n",
    "print(f\"Loading filtered data from {FILTERED_DATA_PATH}...\")\n",
    "df_cleaned = load_complaint_data(FILTERED_DATA_PATH)\n",
    "\n",
    "if df_cleaned.empty:\n",
    "    print(\"Filtered data not found. Please run '01_eda_preprocessing.ipynb' first.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(df_cleaned)} filtered complaints.\")\n",
    "\n",
    "    # 1. Long narratives are often ineffective when embedded as a single vector.\n",
    "    # Implement a text chunking strategy.\n",
    "    # We will use RecursiveCharacterTextSplitter within `create_and_index_faiss`\n",
    "    # Default parameters for chunking are set in chunk_text function (chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "    # 2. Choose an embedding model.\n",
    "    # A good starting point is sentence-transformers/all-MiniLM-L6-v2.\n",
    "    EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    model = load_embedding_model(EMBEDDING_MODEL_NAME)\n",
    "\n",
    "    if model is None:\n",
    "        print(\"Failed to load embedding model. Exiting.\")\n",
    "    else:\n",
    "        # 3. Embedding and Indexing:\n",
    "        # For each text chunk, generate its vector embedding.\n",
    "        # Create a vector store using FAISS.\n",
    "        # Store the embeddings in the vector database with metadata.\n",
    "\n",
    "        faiss_index, chunk_metadata = create_and_index_faiss(df_cleaned, model, VECTOR_STORE_DIR)\n",
    "\n",
    "        if faiss_index is not None and chunk_metadata:\n",
    "            print(\"\\nFAISS Indexing Complete!\")\n",
    "            print(f\"Total chunks indexed: {len(chunk_metadata)}\")\n",
    "            print(f\"Dimension of embeddings: {faiss_index.d}\")\n",
    "\n",
    "            # --- Optional: Test the search functionality ---\n",
    "            print(\"\\n--- Testing Semantic Search (Top 3 relevant chunks) ---\")\n",
    "            test_query = \"problems with credit report accuracy\"\n",
    "            retrieved_results = semantic_search_faiss(test_query, model, faiss_index, chunk_metadata, k=3)\n",
    "\n",
    "            if retrieved_results:\n",
    "                print(f\"Query: '{test_query}'\")\n",
    "                for i, result in enumerate(retrieved_results):\n",
    "                    print(f\"\\n--- Result {i+1} (Distance: {result['distance']:.4f}) ---\")\n",
    "                    print(f\"Complaint ID: {result['original_complaint_id']}\")\n",
    "                    print(f\"Product: {result['product']}\")\n",
    "                    print(f\"Chunk Text: {result['chunk_text'][:200]}...\") # Print first 200 chars\n",
    "            else:\n",
    "                print(\"No results retrieved for the test query.\")\n",
    "\n",
    "            print(\"\\nFAISS index and metadata successfully saved and tested.\")\n",
    "        else:\n",
    "            print(\"FAISS index creation failed. Check previous logs.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
